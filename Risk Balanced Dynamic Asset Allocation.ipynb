{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3b18d4-e5f8-4160-b797-321895185b3e",
   "metadata": {},
   "source": [
    "# Risk Balancing Asset Allocation Algorithm for Portfolio Management\n",
    "\n",
    "Python-based project that aims to optimize portfolio allocation by implementing a risk management strategy while targeting a specific volatility level. The algorithm distributes investments across different assets to achieve a balanced risk exposure, resulting in a more stable and resilient portfolio with a desired volatility target.\n",
    "\n",
    "Integrated weight scaling by a factor using technical analysis involving price and volume data of individual assets to identify patterns, trends, and indicators that can help predict future price movements. \n",
    "\n",
    "Moving averages, stochastic oscillators, and various chart patterns, trends and estimations are incorporated in these indicators,adjusting the weights of assets in portfolio based on the signals they generate.\n",
    "\n",
    "## Allocation Features\n",
    "\n",
    "* Risk parity alogrithm\n",
    "* Targeted Risk Contribution & Volatility Scaling\n",
    "* Rebalanced weights on frequency\n",
    "* Factor scaling\n",
    "\n",
    "## Financial Models & Analysis\n",
    "* Distance vector estimation & factoring\n",
    "* Kalman Filter\n",
    "* SLSQP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b037755-af1c-49b5-a449-517b69bddb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from datetime import datetime\n",
    "\n",
    "import dataframe_image as dfi\n",
    "from xhtml2pdf import pisa\n",
    "import base64\n",
    "import io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be0ca6-6a7c-4592-9d92-3bf5930aef4a",
   "metadata": {},
   "source": [
    "## Market data\n",
    "\n",
    "Pulled market time series from Yahoo Finance, we will be using S&P500 (`^SPX`), 7-10Y Treasury Bonds(`IEF`), Gold (`GLD`) and Coporate Bonds (`LQD`). Dynamic allocation window will be from 2005 to 2023, rebalanced monthly with a lookback window of 6 months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8847eb5f-9a65-4b30-8b75-463415e313c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['^SPX', 'IEF', 'GLD','LQD']\n",
    "start_date = '2005-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "look_back_time = 6 #6months\n",
    "frequency = 'monthly' # monthly\n",
    "\n",
    "data = yf.download(tickers, start=start_date, end=end_date)['Close'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f36996-74a4-480c-a656-73240fb05dcd",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Ensure cleaned data, NaN values and non zero values are cleaned from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bde47775-bba1-49bd-80cf-0c827e8ff997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLD</th>\n",
       "      <th>IEF</th>\n",
       "      <th>LQD</th>\n",
       "      <th>^SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4696.000000</td>\n",
       "      <td>4696.000000</td>\n",
       "      <td>4696.000000</td>\n",
       "      <td>4696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.735656</td>\n",
       "      <td>100.490266</td>\n",
       "      <td>114.599142</td>\n",
       "      <td>2151.107267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.234050</td>\n",
       "      <td>10.754113</td>\n",
       "      <td>9.677588</td>\n",
       "      <td>1053.974213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.259998</td>\n",
       "      <td>79.589996</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>676.530029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>97.430000</td>\n",
       "      <td>91.607500</td>\n",
       "      <td>107.269997</td>\n",
       "      <td>1295.925049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>121.735001</td>\n",
       "      <td>102.514999</td>\n",
       "      <td>114.475002</td>\n",
       "      <td>1873.860046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>155.842499</td>\n",
       "      <td>107.542501</td>\n",
       "      <td>120.230003</td>\n",
       "      <td>2797.857544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>193.889999</td>\n",
       "      <td>123.059998</td>\n",
       "      <td>139.149994</td>\n",
       "      <td>4796.560059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GLD          IEF          LQD         ^SPX\n",
       "count  4696.000000  4696.000000  4696.000000  4696.000000\n",
       "mean    121.735656   100.490266   114.599142  2151.107267\n",
       "std      38.234050    10.754113     9.677588  1053.974213\n",
       "min      41.259998    79.589996    81.699997   676.530029\n",
       "25%      97.430000    91.607500   107.269997  1295.925049\n",
       "50%     121.735001   102.514999   114.475002  1873.860046\n",
       "75%     155.842499   107.542501   120.230003  2797.857544\n",
       "max     193.889999   123.059998   139.149994  4796.560059"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "308cbb11-1e61-4f0b-9e11-16b5122bbc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLD     False\n",
       "IEF     False\n",
       "LQD     False\n",
       "^SPX    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data < 0 ).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37146e29-ff69-4d5f-b0e9-944d1dae219c",
   "metadata": {},
   "source": [
    "## Basic Portfolio Functions\n",
    "\n",
    "- `portfolio_return(weights, rets)`: This function calculates the portfolio return by taking the dot product of the transpose of the `weights` array a e mean retur ) arra The result is multiplied by 252 to annualize the return.\n",
    "\n",
    "- `portfolio_variance(weights, rets)`: This function computes the portfolio variance by taking the dot product of the transpose of the `weights` array, the covariance matrix of returns (`rets.cov()`), and the `weights` array. The result is multiplied by to annualize the volatility252.\n",
    "\n",
    "- `portfolio_volatility(weights, rets)`: This function calculates the portfolio volatility by taking the square root of the `portfolio_variance` function's output using the `math.sqrt()` function.\n",
    "\n",
    "- `rel_risk_contributions(weights, rets)`: This function determines the relative risk contributions of each asset in the portfolio. It computes the portfolio volatility (`vol`), the covariance matrix (`cov`), and multiplies it by the `weights` array divided by `vol` (`np.dot(cov, weights) / vol`). The result is stored in `mvols`. The relative risk contributions (`rc`) are calculated by multiplying `mvols` with `weights`. Finally, `rrc` (relative risk contributions scaled to sum up to 1) is obtained by dividing `rc` by the sum of `rc`.\n",
    "\n",
    "- `mse_risk_contributions(weights, target, rets)`: This function calculates the mean squared error (MSE) of the relative risk contributions (`rc`) compared to a target array (`target`). It first computes `rc` by calling `rel_risk_contributions(weights, rets)`. Then, it calculates the MSE by squaring the difference between `rc` and `target`, taking the mean, and multiplying it by 100.\n",
    "\n",
    "These functions can be used for portfolio analysis and risk attribution tasks.\n",
    "k attribution tasks.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60170200-e7a4-46c4-9866-8a86f8e42e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(weights, rets):\n",
    "    return np.dot(weights.T, rets.mean()) * 252\n",
    "\n",
    "\n",
    "def portfolio_variance(weights, rets):\n",
    "    return np.dot(weights.T, np.dot(rets.cov(), weights)) * 252\n",
    "\n",
    "\n",
    "def portfolio_volatility(weights, rets):\n",
    "    return math.sqrt(portfolio_variance(weights, rets))\n",
    "\n",
    "\n",
    "def rel_risk_contributions(weights, rets):\n",
    "    vol = portfolio_volatility(weights, rets)\n",
    "    cov = rets.cov()\n",
    "    mvols = np.dot(cov, weights) / vol\n",
    "    rc = mvols * weights\n",
    "    rrc = rc / rc.sum()\n",
    "    return rrc\n",
    "\n",
    "\n",
    "def mse_risk_contributions(weights, target, rets):\n",
    "    rc = rel_risk_contributions(weights, rets)\n",
    "    mse = ((rc - target) ** 2).mean()\n",
    "    return mse * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8feb6-6491-42cc-a1bb-dc2e4ce3ed2e",
   "metadata": {},
   "source": [
    "## Scaling Factor with SMA & EMA\n",
    "\n",
    "### generate_ma_table\r\n",
    "This function computes the percentage difference between the 200-day simple moving average (SMA) and the 20-day exponential moving average (EMA) for each ticker in the provided dataset. The results are then resampled to a monthly frequency, returning the last data point for each month.\r\n",
    "\r\n",
    "Parameters:\r\n",
    "- `data`: DataFrame containing the price data for each ticker.\r\n",
    "- `start_date`: Starting date for the analysis.\r\n",
    "- `end_date`: Ending date for the analysis.\r\n",
    "\r\n",
    "Returns:\r\n",
    "- A DataFrame containing the monthly percentage differences between the 200-day SMA and 20-day EMA for each\n",
    "### generate_signal_table\r\n",
    "This function generates a binary signal based on the difference between the 200-day SMA and the 20-day EMA for each ticker. A `True` signal indicates that the 20-day EMA is above the 200-day SMA, while a `False` signal indicates the opposite. The results are then resampled to a monthly frequency, returning the last data point for each month.\r\n",
    "\r\n",
    "Parameters:\r\n",
    "- `data`: DataFrame containing the price data for each ticker.\r\n",
    "- `start_date`: Starting date for the analysis.\r\n",
    "- `end_date`: Ending date for the analysis.\r\n",
    "\r\n",
    "Returns:\r\n",
    "- A DataFrame containing the monthly binary signals for each\n",
    "\n",
    "### scale_weight_factor\r\n",
    "This function scales the weights of assets based on a provided scaling array. The scaling is determined by specific thresholds in the scaling array. For instance, if a value in the scaling array is greater than 0.002, its corresponding weight is multiplied by 2.5. After scaling, the weights are normalized to ensure they sum up to 1.\r\n",
    "\r\n",
    "Parameters:\r\n",
    "- `weight_arr`: Array containing the weights of the assets.\r\n",
    "- `scale_arr`: Array containing the scaling values for each asset.\r\n",
    "\r\n",
    "Returns:\r\n",
    "- A scaled and normalized weight array.\r\n",
    " ticker.\r\n",
    " ticker.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f03f0a1-5fe9-436b-8551-bf7db6e86a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ma_table(data, start_date, end_date,):\n",
    "    # Create an empty DataFrame to store the moving average differences\n",
    "    ma_diff_table = pd.DataFrame()\n",
    "\n",
    "    for ticker in data.columns:\n",
    "        # Calculate the 200-day moving average for each ticker\n",
    "        ma200 = ta.trend.sma_indicator(data[ticker], window=200)\n",
    "\n",
    "        # Calculate the 20-day exponential moving average for each ticker\n",
    "        ema20 = ta.trend.ema_indicator(data[ticker], window=20)\n",
    "\n",
    "        # Calculate the percentage difference between the 200-day MA and the 20-day EMA\n",
    "        ma_diff_percentage = ((ema20 - ma200) / ma200)\n",
    "\n",
    "        # Add the moving average difference to the ma_diff_table DataFrame\n",
    "        ma_diff_table[ticker] = ma_diff_percentage\n",
    "        ma_diff_table = ma_diff_table.dropna()\n",
    "\n",
    "        monthly_data = ma_diff_table.resample('M').last()\n",
    "        \n",
    "    return monthly_data[tickers]\n",
    "\n",
    "def generate_signal_table(data, start_date, end_date,):\n",
    "    # Create an empty DataFrame to store the moving average differences\n",
    "    ma_diff_table = pd.DataFrame()\n",
    "\n",
    "    for ticker in data.columns:\n",
    "        # Calculate the 200-day moving average for each ticker\n",
    "        ma200 = ta.trend.sma_indicator(data[ticker], window=200)\n",
    "\n",
    "        # Calculate the 20-day exponential moving average for each ticker\n",
    "        ema20 = ta.trend.ema_indicator(data[ticker], window=20)\n",
    "\n",
    "        # Calculate the percentage difference between the 200-day MA and the 20-day EMA\n",
    "        ma_diff_percentage = ((ema20 - ma200) / ma200)\n",
    "\n",
    "        # Add the moving average difference to the ma_diff_table DataFrame\n",
    "        ma_diff_table[ticker] = ma_diff_percentage > 0\n",
    "        ma_diff_table = ma_diff_table.dropna()\n",
    "\n",
    "        monthly_data = ma_diff_table.resample('M').last()\n",
    "        \n",
    "    return monthly_data[tickers]\n",
    "\n",
    "def scale_weight_factor (weight_arr, scale_arr):\n",
    "    # Reshape weight_arr and scale_arr to be 1-dimensional\n",
    "    weight_arr = weight_arr.reshape(-1)\n",
    "    scale_arr = scale_arr.reshape(-1)\n",
    "    \n",
    "    # Initialize an array of ones for the scaling factors\n",
    "    scale_factors = np.ones_like(scale_arr)\n",
    "    # Compute the scale factors for values above 0.005 and below or equal to 0.05\n",
    "    indices = (scale_arr > 0.002) \n",
    "    scale_factors[indices] = 2.5\n",
    "    \n",
    "    indices = (scale_arr < 0.001)\n",
    "    scale_factors[indices] = 0.5\n",
    "    \n",
    "#     indices = (scale_arr > 0.06) \n",
    "#     scale_factors[indices] = 2 - 5 * (scale_arr[indices])\n",
    "    \n",
    "#     # Keep the scale factors at 1.1 for values above 0.05 and below or equal to 0.07\n",
    "#     indices = (scale_arr > 0.05) & (scale_arr <= 0.07)\n",
    "#     scale_factors[indices] = 2\n",
    "    \n",
    "    #Compute the scale factors for values above 0.07\n",
    "#     indices = scale_arr >= 0.10\n",
    "#     scale_factors[indices] = 2 - * (scale_arr[indices] - 0.005)\n",
    "    \n",
    "    # Scale the elements in weight_arr by their corresponding scale factor\n",
    "    weight_arr *= scale_factors\n",
    "    # Normalize the weights so they sum up to 1\n",
    "\n",
    "    \n",
    "    if np.sum(weight_arr) > 1:\n",
    "        return weight_arr / np.sum(weight_arr)\n",
    "    \n",
    "    return weight_arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ece45-0b1c-4fe3-a072-9c068376aa8f",
   "metadata": {},
   "source": [
    "## Targeted Risk Contribution Function\n",
    "\n",
    "### risk_parity\r\n",
    "This function determines the optimal asset weights for a portfolio based on the risk parity approach, ensuring each asset contributes equally to the overall portfolio risk. The function uses the SLSQP optimization algorithm to minimize the mean squared error between the relative risk contributions of the assets and a given target. If any asset's relative risk contribution falls below a threshold, a penalty-based approach is applied, and the optimization is repeated using the 'trust-constr' algorithm. The optimal weights are then scaled to achieve a desired portfolio volatility. If the sum of the scaled weights exceeds 1, they are normalized.\r\n",
    "\r\n",
    "Parameters:\r\n",
    "- `target`: Array of target risk contributions for each asset.\r\n",
    "- `target_vol`: Desired portfolio volatility.\r\n",
    "- `returns`: DataFrame containing historical returns for each asset.\r\n",
    "- `tickers`: List of asset tickers.\r\n",
    "\r\n",
    "Returns:\r\n",
    "- An array of optimal asset weights that achieve risk parity while targeting the specified portfolio v\n",
    "\n",
    "### Note\n",
    "Some parts of the code are commented out as they were intended to provide additional checks for risk contribution thresholds. If needed, these lines can be uncommented.olatility.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ae10f4-d0ee-4ad6-928e-c24914bcab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_parity(target, target_vol, returns,tickers):\n",
    "    \n",
    "    noa = len(tickers)\n",
    "    weight = np.ones(noa) / noa\n",
    "    \n",
    "    bnds = noa * [(0.10, None),]  # Lower bound set to 0\n",
    "    # The constraint that weights must sum to 1\n",
    "    cons = ({'type': 'eq', 'fun': lambda w:  np.sum(w) - 1.0})\n",
    "\n",
    "    opt = minimize(lambda w: mse_risk_contributions(w, target=target,rets=returns),\n",
    "                   weight,\n",
    "                   bounds = bnds,  # added constraints here\n",
    "                   method='SLSQP')  # 'trust-constr' algorithm\n",
    "\n",
    "    optimal_weights = opt['x']\n",
    "    \n",
    "#     ###if weights cant be found with SLSQP -> deploy trust-constr for more stricter check\n",
    "#     if not all(i > 0.09 for i in optimal_weights):\n",
    "#         opt = minimize(lambda w: mse_risk_contributions(w, target=target,rets=returns),\n",
    "#                        optimal_weights,\n",
    "#                        bounds = bnds,\n",
    "#                        constraints = cons,\n",
    "#                        method='trust-constr')  # 'trust-constr' algorithm\n",
    "#         optimal_weights = opt['x']\n",
    "#         print('optimal_weights below level')\n",
    "    \n",
    "    if any(i < 0.05 for i in rel_risk_contributions(optimal_weights,returns)):\n",
    "        threshold = 0.05\n",
    "        def mse_risk_contributions2(weights, target, rets, threshold, penalty_factor):\n",
    "            rc = rel_risk_contributions(weights, rets)\n",
    "            mse = ((rc - target) ** 2).mean()\n",
    "\n",
    "            # Compute the penalty for constraint violation\n",
    "            penalty = penalty_factor * np.sum((threshold - rc[rc < threshold]) ** 2)\n",
    "\n",
    "            return (mse + penalty) * 100\n",
    "        \n",
    "        penalty_factor = 10000 # Adjust this to make the constraint more or less strict\n",
    "\n",
    "        opt = minimize(lambda w: mse_risk_contributions2(w, target=target, rets=returns, threshold=threshold, penalty_factor=penalty_factor),\n",
    "                       weight,\n",
    "                       bounds=bnds,\n",
    "                       method='trust-constr')\n",
    "\n",
    "        optimal_weights = opt['x']\n",
    "\n",
    "    \n",
    "    unscaled_vol = portfolio_volatility(optimal_weights, returns)\n",
    "    scale_factor = target_vol / unscaled_vol\n",
    "    optimal_weights_scaled = optimal_weights * scale_factor\n",
    "    sum_weights = np.sum(optimal_weights_scaled)\n",
    "\n",
    "        \n",
    "    \n",
    "    if sum_weights > 1:\n",
    "        normalized_weights = optimal_weights_scaled / sum_weights\n",
    "        return normalized_weights\n",
    "    return optimal_weights_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321379a8-7b8e-471d-926b-4978ce5331a4",
   "metadata": {},
   "source": [
    "## Dynamic Asset Allocation Strategy\n",
    "\n",
    "### risk_balance\r\n",
    "This function determines the optimal asset weights for a portfolio based on the risk parity approach over a specified time period. The portfolio is rebalanced at a specified frequency (either weekly or monthly). For each rebalancing period, the function calculates the risk contributions, portfolio volatility, and leverage. The function starts by downloading historical data for the specified tickers and calculates the logarithmic returns. It then uses the `risk_parity` function to determine the optimal weights for each rebalancing period, considering the risk contributions and the desired portfolio volatility. The weights are further adjusted based on moving average differences using the `scale_weight_factor` function. The function constructs tables for weights, risk contributions, portfolio volatility, and leverage for each rebalancing period and returns a consolidated table containing all this information.\r\n",
    "\r\n",
    "Parameters:\r\n",
    "- `tickers`: List of asset tickers.\r\n",
    "- `start_date`: Starting date for the analysis.\r\n",
    "- `end_date`: Ending date for the analysis.\r\n",
    "- `look_back_time`: Number of months to look back for calculating returns.\r\n",
    "- `frequency`: Rebalancing frequency, either 'weekly' or 'monthly'.\r\n",
    "\r\n",
    "Returns:\r\n",
    "- A DataFrame containing the optimal asset weights, risk contributions, portfolio volatility, and leverage for each rebalancing period.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96898d53-e3c6-45df-beae-5880d53a8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_balance(tickers,start_date,end_date,look_back_time, frequency):\n",
    "    \n",
    "    ###### Extra for Distance\n",
    "    \n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Download historical data as dataframe\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)\n",
    "\n",
    "    # Use only Adjusted Close prices\n",
    "    data = data['Close']\n",
    "\n",
    "    # Calculate returns\n",
    "    data = data.dropna()\n",
    "    \n",
    "    ma_diff_table = generate_ma_table(data,start_date,end_date) # 2005-10-31\t0.072032\t-0.003128\t-0.005133\t-0.003325\n",
    "\n",
    "    rets = np.log(data / data.shift(1))\n",
    "\n",
    "    noa = len(tickers) # number of assets\n",
    "\n",
    "    weight = np.ones(noa) / noa\n",
    "\n",
    "    # Rebalancing monthly\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    current_date = start_date + relativedelta(months=look_back_time) # start after 6 months\n",
    "\n",
    "    weights_table = []\n",
    "    risk_table = []\n",
    "    volatility_table = []\n",
    "\n",
    "\n",
    "    # Initialize the tables\n",
    "    weights_table = []\n",
    "    risk_table = []\n",
    "    volatility_table = []\n",
    "    leverage_table = []\n",
    "\n",
    "    # Now start the loop\n",
    "    while current_date <= end_date:\n",
    "        # Select the relevant six months of returns\n",
    "        six_month_data = rets[(rets.index < current_date) & (rets.index >= current_date - relativedelta(months=look_back_time))]\n",
    "        \n",
    "        scale_arr = ma_diff_table[(ma_diff_table.index.year == current_date.year) & (ma_diff_table.index.month == current_date.month)].values\n",
    "        \n",
    "        target = np.ones(noa) / noa\n",
    "        optimal_weights = risk_parity([0.40,0.40,0.10,0.10],0.10, six_month_data,tickers)\n",
    "        \n",
    "        if scale_arr.size != 0:\n",
    "            optimal_weights = scale_weight_factor(optimal_weights,scale_arr)\n",
    "\n",
    "        # Weight table\n",
    "        weights_table.append(pd.Series(optimal_weights, index=tickers, name=current_date))\n",
    "\n",
    "        # Calculate and add risk contributions to risk_table\n",
    "        risk_contributions = rel_risk_contributions(optimal_weights, six_month_data)\n",
    "        risk_table.append(pd.Series(risk_contributions, index=tickers, name=current_date))\n",
    "\n",
    "        # Calculate and add volatility to vol_table\n",
    "        # Calculate and add annualized portfolio volatility to volatility_table\n",
    "        port_volatility = portfolio_volatility(optimal_weights, six_month_data)\n",
    "        volatility_table.append(pd.Series(port_volatility, index=['Volatility'], name=current_date))\n",
    "\n",
    "        #Leverage\n",
    "        total_leverage = sum(optimal_weights)\n",
    "        leverage_table.append(pd.Series(total_leverage, index=['Leverage'],name=current_date))\n",
    "        \n",
    "        # Update current_date based on specified frequency\n",
    "        if frequency == 'weekly':\n",
    "            current_date = current_date + pd.DateOffset(weeks=1)\n",
    "        elif frequency == 'monthly':\n",
    "            current_date = current_date + relativedelta(months=1)\n",
    "        else:\n",
    "            print(\"Invalid frequency input. Please choose either 'weekly' or 'monthly'.\")\n",
    "            return None\n",
    "        \n",
    "#         if any(i < 0.04 for i in rel_risk_contributions(optimal_weights,six_month_data)):\n",
    "#             print(current_date)\n",
    "#             print(rel_risk_contributions(optimal_weights,six_month_data))\n",
    "\n",
    "\n",
    "        \n",
    "    weights_table = pd.concat(weights_table, axis=1).T\n",
    "    risk_table = pd.concat(risk_table, axis=1).T\n",
    "    volatility_table = pd.concat(volatility_table, axis=1).T\n",
    "    leverage_table = pd.concat(leverage_table,axis=1).T\n",
    "\n",
    "    final_table = pd.concat([weights_table, risk_table.add_suffix('_risk'), volatility_table, leverage_table], axis=1)\n",
    "\n",
    "\n",
    "#     final_table = final_table.applymap(lambda x: \"{:.0f}%\".format(x*100))\n",
    "\n",
    "    final_table = final_table.applymap(lambda x: x*100)\n",
    "    final_table = final_table.round(2)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "#     pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    col_order = list(tickers) + [ticker + '_risk' for ticker in tickers] + ['Volatility'] + ['Leverage']\n",
    "    \n",
    "    return final_table[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b22a7-f63e-4473-b33b-231363c66a27",
   "metadata": {},
   "source": [
    "## Creating Dataframe\n",
    "\n",
    "### df2\n",
    "The provided code segment executes the `risk_balance` function, which determines the optimal asset allocation for a portfolio based on the risk parity approach over a specified time frame. The function's output, a DataFrame named `df2`, contains details about the optimal asset weights, risk contributions, portfolio volatility, and leverage for each rebalancing period. The index of this DataFrame, originally in DateTime format, is then converted to a simple date format for clarity. Finally, the last five rows of the DataFrame are displayed, providing a recent snapshot of the portfolio's risk-balanced allocations and associated metrics.\n",
    "\n",
    "Returns:\n",
    "- A Snapshot of the most recent 5 months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a667256-1691-4517-958b-101f58b53a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SPX</th>\n",
       "      <th>IEF</th>\n",
       "      <th>GLD</th>\n",
       "      <th>LQD</th>\n",
       "      <th>^SPX_risk</th>\n",
       "      <th>IEF_risk</th>\n",
       "      <th>GLD_risk</th>\n",
       "      <th>LQD_risk</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Leverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>30.95</td>\n",
       "      <td>47.68</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.36</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.98</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>30.23</td>\n",
       "      <td>46.17</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.39</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.25</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>42.87</td>\n",
       "      <td>12.46</td>\n",
       "      <td>16.35</td>\n",
       "      <td>28.33</td>\n",
       "      <td>57.77</td>\n",
       "      <td>8.36</td>\n",
       "      <td>11.45</td>\n",
       "      <td>22.41</td>\n",
       "      <td>9.41</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-01</th>\n",
       "      <td>40.66</td>\n",
       "      <td>11.70</td>\n",
       "      <td>15.47</td>\n",
       "      <td>32.17</td>\n",
       "      <td>55.16</td>\n",
       "      <td>8.16</td>\n",
       "      <td>11.58</td>\n",
       "      <td>25.09</td>\n",
       "      <td>8.58</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>54.97</td>\n",
       "      <td>15.50</td>\n",
       "      <td>20.42</td>\n",
       "      <td>9.11</td>\n",
       "      <td>74.55</td>\n",
       "      <td>11.88</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>10.04</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ^SPX    IEF    GLD    LQD  ^SPX_risk  IEF_risk  GLD_risk  \\\n",
       "2023-04-01  30.95  47.68  11.01  10.36      40.00     40.00     10.00   \n",
       "2023-05-01  30.23  46.17  11.20  12.39      40.00     40.00     10.00   \n",
       "2023-06-01  42.87  12.46  16.35  28.33      57.77      8.36     11.45   \n",
       "2023-07-01  40.66  11.70  15.47  32.17      55.16      8.16     11.58   \n",
       "2023-08-01  54.97  15.50  20.42   9.11      74.55     11.88     13.27   \n",
       "\n",
       "            LQD_risk  Volatility  Leverage  \n",
       "2023-04-01     10.00       10.98     100.0  \n",
       "2023-05-01     10.00       10.25     100.0  \n",
       "2023-06-01     22.41        9.41     100.0  \n",
       "2023-07-01     25.09        8.58     100.0  \n",
       "2023-08-01      0.31       10.04     100.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = risk_balance(tickers,start_date,end_date,look_back_time, 'monthly')\n",
    "df2.index = df2.index.date\n",
    "df2.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
